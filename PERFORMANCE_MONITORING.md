# Performance Monitoring & PR Comments

This project includes automated performance monitoring that posts benchmark results as comments on pull requests.

## üéØ Overview

Every PR that modifies source code triggers an automated performance benchmark that compares the OLD (monolithic) vs NEW (refactored) implementation and posts results as a PR comment.

## üìä What Gets Benchmarked

The benchmark runs on a comprehensive test file:
- **File**: `AllUseCases.tsx` (249 KB)
- **Lines**: 8,114 lines of code
- **className usages**: 1,481 Tailwind class usages
- **Test cases**: All real-world patterns from the example project

## ü§ñ Automated PR Comments

When you create a PR, the GitHub Action will:

1. **Build** both OLD and NEW versions
2. **Run** the benchmark 5 times for statistical accuracy
3. **Analyze** performance differences
4. **Post** a formatted comment with:
   - Performance comparison table
   - Memory usage stats
   - Analysis with clear verdict (‚úÖ/‚ö†Ô∏è/‚ùå)
   - Architecture benefits explanation
   - Full benchmark output (collapsible)

### Example PR Comment

```markdown
## üìä Performance Benchmark Results

### Test File Details
- **File**: AllUseCases.tsx
- **Size**: 249.00 KB
- **className usages**: 1,481
- **Invalid classes**: 278

### Performance Comparison

| Implementation | Run 1 | Run 2 | Run 3 | Run 4 | Run 5 | **Average** | Status |
|---|---|---|---|---|---|---|---|
| üÜï **NEW** (Refactored) | 8.30ms | 7.30ms | 9.21ms | 10.40ms | 11.30ms | **9.30ms** | Clean Architecture |
| üì¶ **OLD** (Monolithic) | 13.85ms | 11.55ms | 5.73ms | 11.33ms | 7.08ms | **9.91ms** | Monolithic |

### Analysis
‚úÖ **NEW is within acceptable range (-6.1% difference)**

...
```

## üìà Performance Thresholds

The comment uses emoji indicators:

| Emoji | Meaning | Threshold |
|---|---|---|
| ‚úÖ | Acceptable | NEW within 10% of OLD |
| ‚ö†Ô∏è | Warning | NEW 10-50% slower |
| ‚ùå | Regression | NEW >50% slower |

> **Note**: First-run benchmarks may show NEW slightly slower due to Clean Architecture layers, but repeated validations are **10-95x faster** with LRU caching (typical IDE workflow).

## üõ†Ô∏è Local Development

### Run Benchmark Locally

```bash
# Quick benchmark (build + run)
npm run benchmark

# Generate markdown report
npm run benchmark:report

# View latest report
cat performance/results/latest-report.md
```

### Files Created

1. **`.github/workflows/performance.yml`**
   - GitHub Action workflow for PR benchmarks
   - Triggers on PRs that modify src/ or performance/
   - Posts results as PR comments

2. **`performance/format-benchmark-report.ts`**
   - Formats benchmark results as markdown
   - Calculates performance verdicts
   - Generates detailed reports

3. **`performance/results/latest-report.md`**
   - Latest benchmark report (auto-generated)
   - Useful for local review

4. **Package.json scripts:**
   - `npm run benchmark` - Run full benchmark
   - `npm run benchmark:report` - Generate report from results

## üîç Understanding Results

### Real-World Performance

The benchmark measures **cold-start** performance (first validation), but the NEW implementation excels in **real-world usage**:

**Typical IDE Editing Session:**
```
Action                     OLD      NEW      Winner
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Open file                 4.81ms   6.16ms   OLD
Type (trigger validation) 4.81ms   0.61ms   NEW ‚úÖ
Type (trigger validation) 4.81ms   0.61ms   NEW ‚úÖ
Type (trigger validation) 4.81ms   0.61ms   NEW ‚úÖ
Save file                 4.81ms   0.61ms   NEW ‚úÖ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total session:           28.86ms   9.21ms   NEW wins by 68%!
```

### Why NEW Can Be Slower (First Run)

The NEW implementation has slight overhead on first validation:
- **Service layer abstraction** (~0.3-0.5ms)
- **Object creation** (~0.2-0.3ms)
- **Diagnostic processing** (~0.3-0.5ms)

**Total overhead**: ~1.35ms per file (first validation only)

### Why NEW Is Faster (Repeated Runs)

- **LRU cache**: Validates 2,000 most recent classes instantly
- **Common classes**: `flex`, `p-4`, `bg-white` cached across all files
- **Smart caching**: Per-instance cache persists during editing session

**Speedup**: 10-95x faster on cache hits (typical for repeated validations)

## üìö Related Documentation

- **Performance Analysis**: See [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) for detailed analysis
- **Architecture**: See [ARCHITECTURE.md](./ARCHITECTURE.md) for design decisions
- **Benchmarks**: See [performance/README.md](./performance/README.md) for benchmark details
- **Workflow Docs**: See [.github/workflows/README.md](./.github/workflows/README.md) for CI setup

## üéØ Best Practices

### For PR Authors
1. Check the performance comment on your PR
2. ‚úÖ Green verdict = Good to go
3. ‚ö†Ô∏è Warning = Review if architectural changes are worth the trade-off
4. ‚ùå Regression = Investigate and optimize before merging

### For Reviewers
1. Review performance comment alongside code changes
2. Consider real-world usage patterns (repeated validations)
3. Weigh performance against architecture benefits
4. Check full benchmark output in comment details if needed

### Performance Optimization Tips
If you see a regression:
1. Check if changes affect hot paths (AST traversal, extraction)
2. Profile with `performance/profile-bottlenecks.ts`
3. Consider caching opportunities
4. Review object allocation patterns
5. Benchmark locally: `npm run benchmark`

## üöÄ Future Enhancements

Potential improvements to performance monitoring:
- [ ] Track performance trends over time
- [ ] Compare against baseline branch
- [ ] Add performance budgets (fail PR if >X% slower)
- [ ] Benchmark different file sizes (small, medium, large)
- [ ] Add memory regression detection
- [ ] Integration with performance tracking services

## üìù Troubleshooting

### Comment not appearing on PR
- Check GitHub Actions tab for workflow status
- Verify workflow has `pull-requests: write` permission
- Check if PR modifies files in trigger paths

### Benchmark shows unexpected results
- Verify test file hasn't been modified
- Check if OLD version exists (`lib/index.old.js`)
- Review full output in collapsed section of comment
- Run locally: `npm run benchmark`

### Want to update report format
1. Edit `performance/format-benchmark-report.ts`
2. Test locally: `npm run benchmark:report`
3. Update `.github/workflows/performance.yml` if needed
4. Submit PR to review changes
